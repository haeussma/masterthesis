# Introduction

Reproducible research is the cornerstone of scientific advances and builds the core principle of the scientific method itself. Within the last decade, an increasing number of reports raised attention on unreproducible results across various scientific discipline {cite}`begley2015reproducibility`. Reportedly, more than 70 % of researchers were not able to reproduce the results of another researcher, whereas more than 50 % were not able to reproduce their own findings {cite}`baker2016reproducibility`.
Since reproducibility is a non-standardized term, it often serves as a vague umbrella term for mingling (i) repeatable analysis based on given information by the same scientist, (ii) reproducible analysis based on given information by another scientist, or (iii) replicable analysis with new information by another scientist.
Therefore, reproducibility is not an absolute term but rather relative, depending on the scope of the notion {cite}`goodman2016does`. Goodman et. al. proposed to combine the word reproducibility with its relative scope, hence subdividing reproducibility in methods reproducibility, results reproducibility and inferential reproducibility. According to Goodman, 'methods reproducibility refers to the provision of enough detail about study procedures and data so the same procedures could, in theory or in actuality, be exactly repeated.'. Results reproducibility requires methodological reproducibility, whereas same results are obtained from an independent study. Inferential reproducibility is given, if qualitatively similar conclusions are drawn based on the results of independent studies or reanalysis of a given study. Therefore, inferential reproducibility constitutes the highest level of reproducibility.  
Possible reasons for non-reproducible experiments are broadly discussed and range from study design over publication bias to inappropriate practice of science {cite}`munafo2017manifesto`, {cite}`miyakawa2020no` {cite}`baker2016reproducibility`. Once published, the results of non-reproducible studies are harmful for science, since the reported results along the generated data assets are likely false, since non-reproducible and may therefore lead to wrong conclusions in future studies.

Low reproducibility also affect the field of enzymology, whereas varying experimental standards are described as the leading cause {cite}`bell2021biocatalysis`. With the aim to increase reproducibility on biocatalytic experiments the STRENDA commission has defined standards for reporting enzymology data (STRENDA) {cite}`tipton2014standards`. The [guidelines](https://www.beilstein-institut.de/en/projects/strenda/guidelines/) recommend to report on identity information of the enzyme, enzyme preparation steps, storage conditions, assay conditions and method, as well as enzyme activity with the corresponding kinetic parameters and units. Furthermore, the precision of measurements and preferably the raw data itself should be shared. Hence, the STRENDA guidelines pave the way for reproducible and therefore reusable functional enzymology data.  
Besides the reproducibility of data, availability of data assets must be given in order to enable reuse of extant data. This is especially important to enable the application of big data technologies like machine learning which rely on large amounts of high quality data. In the field of biocatalysis, machine learning bares the potential to investigate how the structures of an enzyme is related to its catalytic properties. Thereby, valuable conclusions for enzyme engineering might be drawn.
One prerequisite for applying big data technologies and therefore use their potential in biocatalysis is the availability of data. With the scope to enhance data reusability, FAIR guiding principles for scientific data management were established {cite}`wilkinson2016fair`. The acronym FAIR denotes four foundation principles for contemporary data management in a Findable, Accessible, Interoperable and Reusable fashion. Special emphasis is payed that machines are able to automatically find and use the data, due to their fundamental importance in modern science. Thereby, (meta)data should be findable by a globally unique identifier. Data should be accessible by an standardized and open protocol. Interoperability is achieved, if data contains qualitative references to other (meta)data and uses conclusive vocabulary. For reusability, the data needs to be extensively describes with accurate and relevant attributes {cite}`wilkinson2016fair`. Broad application of the stated principles will promote the reuse of data and ultimately amplify the knowledge which can be deducted from each published dataset.

To enable data exchange in biocatalysis the standardized exchange format EnzymeML was developed, obeying to FAIR data principles as well as STRENDA guidelines {cite}`pleiss2021standardized`. Within an EnzymeML document information on the reaction conditions, obtained measurement data, as well as modeling results are stored. Thereby, reaction conditions contain information on the pH value, temperature and the reaction vessel. Each species within an reaction like substrate, product or inhibition species is uniquely labeled with an identifier, which allows referencing the specific species in databases. Thereby, proteins are labeled with their UniProt {cite}`bairoch2005universal` id, and reactants are labeled with their respective SMILES or InChI code.  
A special focus of the EnzymeML format is to store the modeling results which are deducted from the experimental data which are stored alongside.
Modeling results and information on model parameters and model equations can be stored alongside the respective measurement data on which the results are based on. In sum, data and meta data of biocatalytic experiments can be stored and shared between scientists and databases compliant with contemporary data management practices.

In this work, an computational workflow based on EnzymeML for kinetic parameters estimation of enzyme reactions was developed. The workflow should enable comprehensive data analysis starting from raw data of enzyme kinetics experiments to kinetic parameter estimates. The workflow should be iteratively developed by applied by workflow on ongoing research projects of EnzymeML project partners. Therefore, two software packages should be developed, which facilitate the parameter estimation process. Finally, the estimated parameters should be written back to the EnzymeML file, unifying measurement data with information on the applied estimation model as well as the resulting kinetic parameters.
